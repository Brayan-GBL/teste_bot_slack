import io
import re
import csv
import zipfile
import chardet
import pandas as pd
import streamlit as st

# =========================
# Config & Constantes
# =========================
FINAL_HEADER = ('√Årea/Processo envolvido,Respons√°vel SAC,C√≥digo da Ocorr√™ncia,Assunto,Tipo,Status,'
                'Propriet√°rio do SAC Name,Hora de Cria√ß√£o,Hora da modifica√ß√£o,Encerrado em,'
                'Solu√ß√£o de Ensino,Tipo de Venda,C√≥digo SGE,Escola Nome,CNPJ,Raz√£o Social,'
                'Rua de Entrega,Cidade de Entrega,Estado de Entrega,CEP de Entrega,'
                'Contato atualizado,Telefone,Solicita√ß√£o,Filial de origem,RMA DEV. VENDA,RMA 2,'
                'NF para aplica√ß√£o de cr√©dito (Financeiro),Nome da transportadora.,'
                'Cliente ir√° contratar o frete?,"Cliente vai contratar frete, info a transportadora",'
                'N¬∫ do pedido SGE,NF Remessa LNE,N¬∫ da nota de origem,'
                'Qual a flexibilidade de data/hor√°rio sugeridas?,An√°lise Realizada - Log√≠stica,'
                'Parecer da Log√≠stica,NF DEV.COLETA,NF Faturamento,Material Conforme?,'
                'Motivo N√£o Conformidade,Observa√ß√µes Log√≠stica,NF DEV.VENDA FATURAMENTO.,'
                'NF DEV.LOJA FATURAMENTO,NF DEV. SIMP.FAT,N√∫mero contato,'
                'Hor√°rio dispon√≠vel para coleta,Respons√°vel pela entrega,Tem restri√ß√£o de acesso?')

LOG_START_RX = re.compile(r'^\s*["`\']*\s*log[√≠i]stica', re.IGNORECASE)
EXCEL_CELL_LIMIT = 32760  # limite seguro por c√©lula no Excel (~32.767)

# =========================
# Helpers de parsing
# =========================
def detect_decode(data: bytes) -> str:
    # tenta latin-1 primeiro; sen√£o detecta com chardet
    try:
        return data.decode("latin-1")
    except UnicodeDecodeError:
        enc = (chardet.detect(data).get("encoding") or "utf-8")
        return data.decode(enc, errors="replace")

def normalize_newlines(text: str) -> str:
    return text.replace("\r\n", "\n").replace("\r", "\n")

def first_field(line: str) -> str:
    """Retorna o trecho antes do primeiro ';'"""
    i = line.find(";")
    part = line if i < 0 else line[:i]
    part = part.strip()
    if part.startswith('"') and part.endswith('"') and len(part) >= 2:
        part = part[1:-1]
    return part

def is_start(line: str) -> bool:
    # remove BOM/aspas/espa√ßos do come√ßo; aceita Log√≠stica/Logistica (case-insensitive)
    s = re.sub(r'^[\uFEFF\s"\'`]+', '', line or '')
    return bool(LOG_START_RX.match(s))

def rebuild_records(lines):
    """Concatena linhas at√© o pr√≥ximo in√≠cio; n√£o ignora nada."""
    out, buf = [], ""
    for ln in lines:
        if is_start(ln):
            if buf:
                out.append(buf)
            buf = ln
        else:
            if not buf:
                buf = ln
            else:
                buf += ln
    if buf:
        out.append(buf)
    return out

def clean_header_by_name(header: str, filename: str) -> str:
    if re.search(r"sql_SAC_LogDevolucao_CQT", filename, re.I):
        header = header.replace("An√°lise Realizada - Log√≠stica.", "An√°lise Realizada - Log√≠stica")
    if re.search(r"sql_SAC__LogDevolucao_SPE", filename, re.I):
        header = header.replace("Respons√°vel pela entrega .", "Respons√°vel pela entrega")
    return header

# divide linha CSV respeitando aspas
def split_csv_line(line: str, delim: str = ","):
    out, cur, inq = [], [], False
    i = 0
    while i < len(line):
        ch = line[i]
        if ch == '"':
            if inq and i + 1 < len(line) and line[i+1] == '"':
                cur.append('"'); i += 2; continue
            inq = not inq; i += 1; continue
        if ch == delim and not inq:
            out.append(''.join(cur).strip()); cur = []; i += 1; continue
        cur.append(ch); i += 1
    out.append(''.join(cur).strip())
    return out

# =========================
# Builders de sa√≠da
# =========================
def build_onecol_csv(final_lines):
    """CSV com 1 coluna: cada item vira uma linha (sem limites pr√°ticos)."""
    buff = io.StringIO()
    w = csv.writer(buff, delimiter=',', quotechar='"', lineterminator='\r\n')
    for line in final_lines:
        w.writerow([line])
    return buff.getvalue().encode("utf-8")

def build_wide_xlsx(rebuilt, header):
    """XLSX com colunas explodidas por v√≠rgula."""
    rows = [split_csv_line(header)] + [split_csv_line(x) for x in rebuilt]
    df = pd.DataFrame(rows[1:], columns=rows[0])
    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        df.to_excel(writer, sheet_name="Dados", index=False)
    return bio.getvalue()

def build_onecol_xlsx(final_lines):
    """XLSX 1 coluna; divide linha longa em partes __PART_n__ para n√£o estourar o Excel."""
    import openpyxl
    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "Dados"
    for line in final_lines:
        if len(line) <= EXCEL_CELL_LIMIT:
            ws.append([line])
        else:
            idx, part = 0, 1
            step = EXCEL_CELL_LIMIT - 12
            while idx < len(line):
                chunk = line[idx: idx + step]
                ws.append([f"{chunk}__PART_{part}__"])
                idx += step; part += 1
    bio = io.BytesIO()
    wb.save(bio)
    return bio.getvalue()

# =========================
# UI
# =========================
st.set_page_config(page_title="Limpeza CSV SAC", page_icon="üßπ", layout="wide")
st.title("üßπ Limpeza & Convers√£o dos CSVs do SAC")

st.markdown("""
Fa√ßa upload dos **2 CSVs crus** (CQT e SPE).  
O app aplica a tratativa (reconstru√ß√£o ‚ÄúLog√≠stica‚Ä¶‚Äù, limpeza de cabe√ßalho, ordem fixa) e gera:
- **`*_final_onecol.csv`** (1 coluna A ‚Äî ideal p/ Power BI),
- **`*_final_wide.xlsx`** (colunas explodidas),
- **`*_final_onecol.xlsx`** (1 coluna A, com divis√£o segura se exceder o limite do Excel).
""")

files = st.file_uploader("Selecione os CSVs", type=["csv"], accept_multiple_files=True)

col_a, col_b = st.columns([1,1])
with col_a:
    btn = st.button("üöÄ Processar", type="primary", use_container_width=True)

logs = st.empty()
results = []

if btn:
    if not files:
        st.error("Envie pelo menos 1 CSV.")
    else:
        for upl in files:
            name = upl.name
            data = upl.read()
            st.write(f"**Processando**: `{name}`")

            # 1) leitura & normaliza√ß√£o
            text = detect_decode(data)
            lines = [ln.strip() for ln in normalize_newlines(text).split("\n") if ln.strip()]

            # 2) primeiro campo antes de ';'
            ff = [first_field(ln) for ln in lines]
            header = clean_header_by_name(ff[0], name)
            body = ff[1:]

            # 3) for√ßa cabe√ßalho final
            final_header = FINAL_HEADER

            # 4) reconstru√ß√£o
            rebuilt = rebuild_records(body)

            # 5) sa√≠das
            onecol_csv_bytes  = build_onecol_csv([final_header] + rebuilt)
            wide_xlsx_bytes   = build_wide_xlsx(rebuilt, final_header)
            onecol_xlsx_bytes = build_onecol_xlsx([final_header] + rebuilt)

            # bot√µes de download individuais
            st.download_button(
                f"‚¨áÔ∏è {name.replace('.csv','')}_final_onecol.csv",
                onecol_csv_bytes, file_name=f"{name.replace('.csv','')}_final_onecol.csv",
                mime="text/csv", use_container_width=True
            )
            st.download_button(
                f"‚¨áÔ∏è {name.replace('.csv','')}_final_wide.xlsx",
                wide_xlsx_bytes, file_name=f"{name.replace('.csv','')}_final_wide.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
            st.download_button(
                f"‚¨áÔ∏è {name.replace('.csv','')}_final_onecol.xlsx",
                onecol_xlsx_bytes, file_name=f"{name.replace('.csv','')}_final_onecol.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )

            # adiciona ao zip
            results.append((
                name,
                onecol_csv_bytes,
                wide_xlsx_bytes,
                onecol_xlsx_bytes
            ))

        # zip com tudo
        if results:
            zip_buf = io.BytesIO()
            with zipfile.ZipFile(zip_buf, "w", zipfile.ZIP_DEFLATED) as zf:
                for name, onecol_csv, wide_xlsx, onecol_xlsx in results:
                    base = name.rsplit(".", 1)[0]
                    zf.writestr(f"{base}_final_onecol.csv", onecol_csv)
                    zf.writestr(f"{base}_final_wide.xlsx",  wide_xlsx)
                    zf.writestr(f"{base}_final_onecol.xlsx", onecol_xlsx)
            zip_buf.seek(0)
            st.download_button(
                "üì¶ Baixar tudo em ZIP",
                zip_buf, file_name="saidas_tratadas.zip",
                mime="application/zip",
                use_container_width=True
            )

st.caption("Tudo roda local. Se quiser, depois a gente integra isso a n8n/Drive.")
